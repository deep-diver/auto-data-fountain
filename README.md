# ⛲️ Auto Data Fountain

The goal of Auto Data Fountain is to generate synthetic data in order to fine-tune a large language model for arbitrary situations in a systematic way. Auto Data Fountain generates synthetic data by leaveraging the power of Large Language Mode(LLM). Currently supported LLM is Google's Gemini Pro, and GPT4 will be supported soon. 

## Motivation

There are many well-known and well-documented contents on how to fine-tune large language models. However, it is hard to collect hundreds of thousands of data for the fine-tuning. To this end, there have been various methods proposed to generate synthetic dataset such as [Stanford Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html), [WizardLM's Evol-Instruct](https://github.com/nlpxucan/WizardLM), and so on. 

Those synthetic data generation methods define seed prompts, then LLM(mostly GPT4) continues to generate (prompt, output) pairs derived from it in various directions. The fine-tuned LLMs on the datasets generated by these methods has shown good results so far. However, there are two main concerns of these methods, and Auto Data Fountain tries to solve them in the follwoing manner.

1. The seed prompts were manually picked.

2. These methods were applied to build up a sort of general purpose fine-tuned LLMs. General purpose doesn't mean the fine-tuned LLMs are in the level of expert to solve problems on any arbitrary tasks. Rather it tries to give you general answers on various tasks. This is why some modern datasets (in 2023~2024) are constructed by merging lots of different datasets from various sources. However, we can not find possible dataset on every single possible scenarios.

However, it is hard to collect hundreds of thousands of task specific data for the fine-tuning. 

## Basics

1. define your own setup in `setup.yaml` and `diagram.mermaid` in a directory. The `setup.yaml` defines basic information such as system prompt, roles of a user and an assistant while `diagram.mermaid` focuses on the entities and their relationship. 

Below shows an example structure of the `setup.yaml` for a basic marriage counsel.
```yaml
initial_prompt: |
  ....

derivational_prompt: |
  ....

output_format: | 
  The generated conversations are recorded in a valid JSON as
  {"conversations":[{"user": text, "assistant": text},...]}.  

delimiter: "------------------------------"

user_role: COUNSELEE
assistant_role: COUNSELOR

seed_evolving_directions:
  - general

derivational_evolving_directions:
  - general
  - in-depth
```

Now, lets have a look into the `diagram.mermaid` for the situation. Note that you can specify much detailed attributes of each entity, and you can also give extra description of the relationship in comments. If you wish to understand of the meaning of it, read this document in raw format since comments are invisible in graphic mode.
```mermaid
erDiagram
    COUNSELOR ||--|{ COUNSELEE : "provides counseling to"

    %% Comments for relationship attributes
    %% Start date: 2024-02-14
    %% Frequency: Weekly
    %% Topic: marriage guidance
```

2. run the following CLI
```bash
$ pip install -r requirements.txt
$ python src/main.py \ 
--gemini-api-key "..." \ 
--target-folder samples/marriage_counsel
```
